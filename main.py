from fastapi import FastAPI, Depends, HTTPException, status
from fastapi.staticfiles import StaticFiles
from sqlalchemy.orm import Session
from typing import List
from datetime import datetime, timedelta
import random
import os

import crud
import models
import schemas
from database import SessionLocal, engine, Base

# –°–æ–∑–¥–∞–µ–º –æ–±—ä–µ–∫—Ç FastAPI
app = FastAPI(title="Microclimate Monitoring API")


@app.on_event("startup")
def startup_event():
    """–ü—Ä–∏ –∑–∞–ø—É—Å–∫–µ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–æ–∑–¥–∞—ë–º —Ç–∞–±–ª–∏—Ü—ã, –µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç."""
    try:
        print("üöÄ –°–æ–∑–¥–∞—ë–º —Ç–∞–±–ª–∏—Ü—ã SQLite (–µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç)")
        Base.metadata.create_all(bind=engine)
        
        # –°–æ–∑–¥–∞—ë–º –ø–∞–ø–∫—É –¥–ª—è –æ—Ç—á—ë—Ç–æ–≤
        os.makedirs("reports", exist_ok=True)
        print("üìÅ –ü–∞–ø–∫–∞ reports/ –≥–æ—Ç–æ–≤–∞")
        
    except Exception as e:
        print(f"‚ö†Ô∏è Warning: failed to create tables on startup: {e}")

# –ü–æ–¥–∫–ª—é—á–∞–µ–º —Å—Ç–∞—Ç–∏—á–µ—Å–∫–∏–µ —Ñ–∞–π–ª—ã –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è –æ—Ç—á—ë—Ç–æ–≤
app.mount("/reports", StaticFiles(directory="reports"), name="reports")

# --- Dependency (–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –ë–î) ---
def get_db():
    """–°–æ–∑–¥–∞–µ—Ç –∏ –∑–∞–∫—Ä—ã–≤–∞–µ—Ç —Å–µ—Å—Å–∏—é –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()

# -------------------------------------------------------------------
# üìç 1. –õ–û–ö–ê–¶–ò–ò –ò –î–ê–¢–ß–ò–ö–ò
# -------------------------------------------------------------------

@app.get("/api/locations", response_model=List[schemas.LocationRead])
def get_locations(db: Session = Depends(get_db)):
    """–ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –ª–æ–∫–∞—Ü–∏–π (–∫–∞–±–∏–Ω–µ—Ç–æ–≤) –¥–ª—è –≤—ã–ø–∞–¥–∞—é—â–µ–≥–æ —Å–ø–∏—Å–∫–∞."""
    return crud.get_all_locations(db)

@app.get("/api/sensors/{location_id}", response_model=List[schemas.SensorRead])
def get_sensors_by_location_id(location_id: int, db: Session = Depends(get_db)):
    """
    –ü–æ–ª—É—á–∏—Ç—å –¥–∞—Ç—á–∏–∫–∏ + –°–ò–ú–£–õ–Ø–¶–ò–Ø –§–ò–ó–ò–ö–ò.
    –ü—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –º—ã –ø—Ä–æ–≤–µ—Ä—è–µ–º, –Ω—É–∂–Ω–æ –ª–∏ '–ø–æ–¥—Ç—è–Ω—É—Ç—å' —Ç–µ–∫—É—â–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –∫ —Ü–µ–ª–µ–≤–æ–º—É.
    """
    
    sensors = crud.get_sensors_by_location(db, location_id)
    
    result = []
    for sensor in sensors:
        last_measure = crud.get_last_measurement(db, sensor.id)
        current_val = last_measure.value if last_measure else 0.0
        
        # --- –õ–û–ì–ò–ö–ê –°–ò–ú–£–õ–Ø–¶–ò–ò (PHYSICS ENGINE) ---
        if sensor.is_active and sensor.target_value is not None:
            diff = sensor.target_value - current_val
            
            if abs(diff) > 0.1:
                time_since_last = datetime.utcnow() - last_measure.timestamp if last_measure else timedelta(seconds=100)
                
                if time_since_last.total_seconds() > 5:
                    step = diff * 0.1
                    
                    if abs(step) < 0.1:
                        step = 0.1 if diff > 0 else -0.1
                        
                    noise = random.uniform(-0.05, 0.05)
                    new_val = current_val + step + noise
                    
                    new_measure = models.Measurement(
                        sensor_id=sensor.id,
                        location_id=sensor.location_id,
                        value=round(new_val, 2),
                        timestamp=datetime.utcnow()
                    )
                    db.add(new_measure)
                    db.commit()
                    
                    current_val = new_val
        
        sensor_data = schemas.SensorRead.from_orm(sensor)
        sensor_data.last_value = round(current_val, 1)
        result.append(sensor_data)
        
    return result

@app.patch("/api/sensors/{sensor_id}", response_model=schemas.SensorRead)
def update_sensor_settings(
    sensor_id: int, 
    update_data: schemas.SensorUpdate, 
    user_id: int = 1,
    db: Session = Depends(get_db)
):
    """–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –¥–∞—Ç—á–∏–∫–æ–º —Å –∑–∞–ø–∏—Å—å—é –≤ –õ–û–ì–ò."""
    sensor = db.query(models.Sensor).filter(models.Sensor.id == sensor_id).first()
    if not sensor:
        raise HTTPException(status_code=404, detail="Sensor not found")
    
    action_text = []
    
    if update_data.is_active is not None and update_data.is_active != sensor.is_active:
        sensor.is_active = update_data.is_active 
        status = "–í–∫–ª—é—á–∏–ª" if update_data.is_active else "–í—ã–∫–ª—é—á–∏–ª"
        action_text.append(f"{status} –¥–∞—Ç—á–∏–∫ {sensor.name}")
        
    if update_data.target_value is not None:
        if update_data.target_value != sensor.target_value:
            sensor.target_value = update_data.target_value 
            action_text.append(f"–ò–∑–º–µ–Ω–∏–ª {sensor.name} –Ω–∞ {update_data.target_value}")

    if action_text:
        db.commit()
        db.refresh(sensor)
        
        full_action_description = ", ".join(action_text)
        new_log = models.ActionLog(
            user_id=user_id,
            action=full_action_description,
            timestamp=datetime.utcnow()
        )
        db.add(new_log)
        db.commit()

    last_measure = crud.get_last_measurement(db, sensor.id)
    updated_sensor = schemas.SensorRead.from_orm(sensor)
    updated_sensor.last_value = last_measure.value if last_measure else 0.0
    
    return updated_sensor

# -------------------------------------------------------------------
# üìä 2. –ê–ù–ê–õ–ò–¢–ò–ö–ê –ò –î–≠–®–ë–û–†–î
# -------------------------------------------------------------------

@app.get("/api/dashboard/stats")
def get_dashboard_stats(db: Session = Depends(get_db)):
    """–°—á–∏—Ç–∞–µ—Ç —Å—Ä–µ–¥–Ω—é—é —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—É –∏ –≤–ª–∞–∂–Ω–æ—Å—Ç—å, –∞ —Ç–∞–∫–∂–µ –∏—Ö –ø—Ä–æ—Ü–µ–Ω—Ç–Ω–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ –∑–∞ 24 —á–∞—Å–∞."""
    sensors = db.query(models.Sensor).all()
    
    cur_temp_vals = []
    cur_hum_vals = []
    old_temp_vals = []
    old_hum_vals = []

    time_24h_ago = datetime.utcnow() - timedelta(days=1)

    for sensor in sensors:
        last_measure = crud.get_last_measurement(db, sensor.id)
        
        old_measure = db.query(models.Measurement)\
            .filter(models.Measurement.sensor_id == sensor.id, 
                    models.Measurement.timestamp <= time_24h_ago)\
            .order_by(models.Measurement.timestamp.desc())\
            .first()
        
        if last_measure:
            if sensor.sensor_type.name == "Temperature":
                cur_temp_vals.append(last_measure.value)
                if old_measure: old_temp_vals.append(old_measure.value)
            elif sensor.sensor_type.name == "Humidity":
                cur_hum_vals.append(last_measure.value)
                if old_measure: old_hum_vals.append(old_measure.value)
    
    def get_avg(values):
        return sum(values) / len(values) if values else 0.0
        
    def get_percent_change(current, old):
        if not old or old == 0: return 0.0
        return ((current - old) / old) * 100

    avg_temp_now = get_avg(cur_temp_vals)
    avg_hum_now = get_avg(cur_hum_vals)
    avg_temp_old = get_avg(old_temp_vals)
    avg_hum_old = get_avg(old_hum_vals)

    return {
        "avg_temperature": round(avg_temp_now, 1),
        "avg_humidity": round(avg_hum_now, 1),
        "temp_change": round(get_percent_change(avg_temp_now, avg_temp_old), 1),
        "hum_change": round(get_percent_change(avg_hum_now, avg_hum_old), 1)
    }

@app.get("/analytics/{sensor_id}", response_model=List[schemas.ChartPoint])
def read_analytics(sensor_id: int, days: int = 7, db: Session = Depends(get_db)):
    """–î–∞–Ω–Ω—ã–µ –¥–ª—è –≥—Ä–∞—Ñ–∏–∫–∞"""
    stats = crud.get_analytics_daily(db=db, sensor_id=sensor_id, days=days)
    if not stats:
        return []
    return stats

@app.get("/api/history", response_model=List[schemas.MeasurementRead])
def get_history(sensor_id: int = None, db: Session = Depends(get_db)):
    """–°—ã—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ"""
    query = db.query(models.Measurement)
    if sensor_id:
        query = query.filter(models.Measurement.sensor_id == sensor_id)
    return query.order_by(models.Measurement.timestamp.desc()).limit(100).all()

# -------------------------------------------------------------------
# üìÑ 3. –û–¢–ß–ï–¢–´
# -------------------------------------------------------------------

@app.get("/api/reports", response_model=List[schemas.ReportRead])
def get_reports(db: Session = Depends(get_db)):
    """–°–ø–∏—Å–æ–∫ –æ—Ç—á–µ—Ç–æ–≤"""
    return db.query(models.Report).order_by(models.Report.report_date.desc()).all()

@app.post("/api/reports/generate/{period}", status_code=status.HTTP_201_CREATED)
def generate_report_endpoint(period: str, db: Session = Depends(get_db)):
    """
    –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞ (–Ω–µ–¥–µ–ª—å–Ω—ã–π –∏–ª–∏ –º–µ—Å—è—á–Ω—ã–π).
    –°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ñ–∞–π–ª –ª–æ–∫–∞–ª—å–Ω–æ –≤ –ø–∞–ø–∫—É reports/.
    """
    end_time = datetime.utcnow()
    
    if period == "week":
        start_time = end_time - timedelta(days=7)
        title_prefix = "–ù–µ–¥–µ–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç"
    elif period == "month":
        start_time = end_time - timedelta(days=30)
        title_prefix = "–ú–µ—Å—è—á–Ω—ã–π –æ—Ç—á–µ—Ç"
    else:
        raise HTTPException(status_code=400, detail="Invalid period. Use 'week' or 'month'.")

    # 1. –°–±–æ—Ä –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    report_data = crud.calculate_report_data(db, start_time, end_time)
    
    if not report_data:
        return {"message": f"–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è {title_prefix.lower()} –∑–∞ –ø–µ—Ä–∏–æ–¥: {start_time.strftime('%Y-%m-%d')} - {end_time.strftime('%Y-%m-%d')}"}

    # 2. –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è –æ—Ç—á–µ—Ç–∞
    report_content_lines = [f"{title_prefix} –∑–∞ –ø–µ—Ä–∏–æ–¥ {start_time.strftime('%d.%m.%Y')} - {end_time.strftime('%d.%m.%Y')}\n"]
    report_content_lines.append("=" * 60)
    for data in report_data:
        report_content_lines.append(
            f"\n–õ–æ–∫–∞—Ü–∏—è: {data['location']}\n"
            f"–î–∞—Ç—á–∏–∫: {data['sensor']} ({data['type']})\n"
            f"  ‚Ä¢ –°—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ: {data['avg']}\n"
            f"  ‚Ä¢ –ú–∏–Ω–∏–º—É–º: {data['min']}\n"
            f"  ‚Ä¢ –ú–∞–∫—Å–∏–º—É–º: {data['max']}"
        )
    report_file_content = "\n".join(report_content_lines)
    
    # 3. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ñ–∞–π–ª–∞ –ª–æ–∫–∞–ª—å–Ω–æ
    filename = f"{period}_{end_time.strftime('%Y%m%d_%H%M%S')}.txt"
    file_url = crud.save_report_locally(filename, report_file_content)
    
    # 4. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –æ—Ç—á–µ—Ç–∞ –≤ –ë–î
    report_title = f"{title_prefix} ({start_time.strftime('%d.%m')} - {end_time.strftime('%d.%m')})"
    
    new_report = models.Report(
        title=report_title,
        file_path=file_url,
        report_date=end_time
    )
    db.add(new_report)
    db.commit()

    return {
        "message": "–û—Ç—á–µ—Ç —É—Å–ø–µ—à–Ω–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω.", 
        "title": report_title,
        "report_url": file_url
    }


@app.get("/api/reports/{report_id}/download")
def download_report(
    report_id: int, 
    user_id: int = 1, 
    db: Session = Depends(get_db)
):
    """–ü–æ–ª—É—á–∏—Ç—å —Å—Å—ã–ª–∫—É –Ω–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ –æ—Ç—á–µ—Ç–∞ —Å –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ–º"""
    report = db.query(models.Report).filter(models.Report.id == report_id).first()
    if not report:
        raise HTTPException(status_code=404, detail="Report not found")

    new_log = models.ActionLog(
        user_id=user_id,
        action=f"–°–∫–∞—á–∞–ª –æ—Ç—á–µ—Ç: {report.title}",
        timestamp=datetime.utcnow()
    )
    db.add(new_log)
    db.commit()

    return {
        "download_url": report.file_path,
        "filename": report.title
    }

# -------------------------------------------------------------------
# üë• 4. –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–ò –ò –õ–û–ì–ò
# -------------------------------------------------------------------

@app.get("/api/users", response_model=List[schemas.UserListDTO])
def get_users(db: Session = Depends(get_db)):
    return crud.get_users_for_ui(db)

@app.get("/api/logs", response_model=List[schemas.ActionLogDTO])
def get_logs(limit: int = 20, db: Session = Depends(get_db)):
    return crud.get_logs_for_ui(db, limit=limit)

# -------------------------------------------------------------------
# üîî 5. –£–í–ï–î–û–ú–õ–ï–ù–ò–Ø
# -------------------------------------------------------------------

@app.get("/api/notifications", response_model=List[schemas.NotificationRead])
def get_notifications(db: Session = Depends(get_db)):
    return db.query(models.Notification).filter(models.Notification.is_completed == False).all()

@app.post("/api/notifications/{notif_id}/complete")
def complete_notification(notif_id: int, db: Session = Depends(get_db)):
    notif = db.query(models.Notification).filter(models.Notification.id == notif_id).first()
    if notif:
        notif.is_completed = True
        db.commit()
    return {"status": "ok"}

# -------------------------------------------------------------------
# üì• 6. –°–õ–£–ñ–ï–ë–ù–´–ï (IoT –∏ Seed)
# -------------------------------------------------------------------

@app.post("/api/measurements", status_code=status.HTTP_201_CREATED)
def record_measurement(
    measurement: schemas.MeasurementCreate, 
    db: Session = Depends(get_db)
):
    sensor = db.query(models.Sensor).filter(models.Sensor.id == measurement.sensor_id).first()
    if not sensor:
        raise HTTPException(status_code=404, detail="Sensor not found")
        
    db_measurement = models.Measurement(
        sensor_id=sensor.id, 
        location_id=sensor.location_id,
        value=measurement.value,
        timestamp=datetime.utcnow()
    )
    
    db.add(db_measurement)
    db.commit()
    return {"status": "recorded", "value": measurement.value}

@app.post("/api/seed_data")
def seed_database(db: Session = Depends(get_db)):
    """–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
    t_temp = db.query(models.SensorType).filter(models.SensorType.name == "Temperature").first()
    if not t_temp:
        t_temp = models.SensorType(name="Temperature", unit="¬∞C")
        db.add(t_temp)
    t_hum = db.query(models.SensorType).filter(models.SensorType.name == "Humidity").first()
    if not t_hum:
        t_hum = models.SensorType(name="Humidity", unit="%")
        db.add(t_hum)
    db.commit()

    existing_count = db.query(models.Location).count()
    NEW_ROOMS_COUNT = 3

    for i in range(1, NEW_ROOMS_COUNT + 1):
        room_number = existing_count + i
        new_loc = models.Location(name=f"–ö–∞–±–∏–Ω–µ—Ç {room_number}")
        db.add(new_loc)
        db.commit()
        db.refresh(new_loc)

        s_temp = models.Sensor(
            name=f"–ö–æ–Ω–¥–∏—Ü–∏–æ–Ω–µ—Ä {room_number}", 
            location_id=new_loc.id, 
            sensor_type_id=t_temp.id, 
            target_value=22.0,
            is_active=True
        )
        s_hum = models.Sensor(
            name=f"–£–≤–ª–∞–∂–Ω–∏—Ç–µ–ª—å {room_number}", 
            location_id=new_loc.id, 
            sensor_type_id=t_hum.id, 
            target_value=45.0,
            is_active=True
        )
        db.add_all([s_temp, s_hum])
        db.commit()
        
        for hour in range(24):
            val_temp = 22.0 + random.uniform(-3, 3) 
            m1 = models.Measurement(
                sensor_id=s_temp.id, 
                location_id=new_loc.id, 
                value=round(val_temp, 1), 
                timestamp=datetime.utcnow() - timedelta(hours=hour)
            )
            val_hum = 45.0 + random.uniform(-10, 10)
            m2 = models.Measurement(
                sensor_id=s_hum.id, 
                location_id=new_loc.id, 
                value=round(val_hum, 1), 
                timestamp=datetime.utcnow() - timedelta(hours=hour)
            )
            db.add_all([m1, m2])

    if not db.query(models.User).filter(models.User.full_name == "Kseniya Kruchina").first():
        u1 = models.User(full_name="Kseniya Kruchina", role="engineer", is_online=True, hashed_password="xhz")
        db.add(u1)
        
    db.commit()
    
    return {"message": f"–£—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω–æ {NEW_ROOMS_COUNT} –Ω–æ–≤—ã—Ö –∫–∞–±–∏–Ω–µ—Ç–∞!"}


# -------------------------------------------------------------------
# üéØ DIPLOMA ENDPOINTS (NEW CRITERIA)
# -------------------------------------------------------------------

@app.get("/api/sensors/{sensor_id}/anomalies")
def analyze_sensor_anomalies(sensor_id: int, days: int = 7, db: Session = Depends(get_db)):
    """
    üéì DIPLOMA CRITERION 2 & 3: –ê–Ω–∞–ª–∏–∑ –∞–Ω–æ–º–∞–ª–∏–π —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏—Ö –∏ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä –º–µ—Ç–æ–¥–æ–≤.
    
    –ü—Ä–æ—Ü–µ—Å—Å:
    1. –ò–∑–≤–ª–µ–∫–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ N –¥–Ω–µ–π –∏–∑–º–µ—Ä–µ–Ω–∏–π
    2. –ü—Ä–∏–º–µ–Ω—è–µ–º –ö–õ–ê–°–°–ò–ß–ï–°–ö–ò–ï –º–µ—Ç–æ–¥—ã (Moving Average, Isolation Forest, Seasonal)
    3. –ü—Ä–∏–º–µ–Ω—è–µ–º –¢–†–ê–ù–°–§–û–†–ú–ï–†-–ø–æ–¥–æ–±–Ω—ã–µ –º–µ—Ç–æ–¥—ã (Time Series Attention, Trend Analysis)
    4. –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã (DIPLOMA CRITERION 3)
    5. –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑
    
    Args:
        sensor_id: ID –¥–∞—Ç—á–∏–∫–∞
        days: –ì–ª—É–±–∏–Ω–∞ –∞–Ω–∞–ª–∏–∑–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 7 –¥–Ω–µ–π)
    
    Returns:
        {
            'sensor_id': int,
            'sensor_name': str,
            'measurements_count': int,
            'analysis': {
                'classical': {...},
                'transformer': {...},
                'comparison': {
                    'models_agree': bool,
                    'consensus_is_anomaly': bool,
                    'agreement_score': float
                }
            }
        }
    """
    try:
        sensor = db.query(models.Sensor).filter(models.Sensor.id == sensor_id).first()
        if not sensor:
            raise HTTPException(status_code=404, detail="Sensor not found")
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–∑–º–µ—Ä–µ–Ω–∏—è –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ N –¥–Ω–µ–π
        measurements = crud.get_sensor_measurements(db, sensor_id, days=days)
        
        if not measurements:
            return {
                'sensor_id': sensor_id,
                'sensor_name': sensor.name,
                'measurements_count': 0,
                'error': 'No measurements found for analysis'
            }
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Å–ø–∏—Å–æ–∫ –∑–Ω–∞—á–µ–Ω–∏–π
        values = [m.value for m in measurements]
        
        # –ò–ú–ü–û–†–¢–ò–†–£–ï–ú –ú–û–î–£–õ–ò –ê–ù–ê–õ–ò–ó–ê
        from anomaly_detection_classical import (
            moving_avg_detector, isolation_forest_detector, seasonal_detector
        )
        from anomaly_detection_transformer import ensemble_detector
        
        # –ö–õ–ê–°–°–ò–ß–ï–°–ö–ò–ï –ú–ï–¢–û–î–´
        classical_result = moving_avg_detector.detect(values)
        if not classical_result['is_anomaly']:
            classical_result = isolation_forest_detector.detect(values)
        if not classical_result['is_anomaly']:
            classical_result = seasonal_detector.detect(values)
        
        # –¢–†–ê–ù–°–§–û–†–ú–ï–† –ú–ï–¢–û–î–´
        transformer_result = ensemble_detector.detect(values)
        
        # –°–†–ê–í–ù–ï–ù–ò–ï –ú–û–î–ï–õ–ï–ô (DIPLOMA CRITERION 3)
        models_agree = classical_result['is_anomaly'] == transformer_result['is_anomaly']
        consensus_is_anomaly = classical_result['is_anomaly'] and transformer_result['is_anomaly']
        
        agreement_score = (
            (1 - abs(classical_result['score'] - transformer_result['score'])) * 0.5 +
            (1 if models_agree else 0) * 0.5
        )
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞ –≤ –ë–î
        analysis_record = models.AnomalyAnalysis(
            sensor_id=sensor_id,
            location_id=sensor.location_id,
            classical_method='ensemble',
            classical_anomaly_score=classical_result['score'],
            classical_is_anomaly=classical_result['is_anomaly'],
            transformer_model='ensemble',
            transformer_anomaly_score=transformer_result['score'],
            transformer_is_anomaly=transformer_result['is_anomaly'],
            models_agreement=models_agree,
            confidence=agreement_score,
            analysis_timestamp=datetime.utcnow()
        )
        db.add(analysis_record)
        db.commit()
        
        return {
            'sensor_id': sensor_id,
            'sensor_name': sensor.name,
            'measurements_count': len(measurements),
            'analysis': {
                'classical': {
                    'is_anomaly': classical_result['is_anomaly'],
                    'score': round(classical_result['score'], 3),
                    'description': classical_result.get('description', ''),
                    'method': 'moving_average + isolation_forest + seasonal'
                },
                'transformer': {
                    'is_anomaly': transformer_result['is_anomaly'],
                    'score': round(transformer_result['score'], 3),
                    'description': transformer_result.get('description', ''),
                    'reconstruction_error': round(transformer_result.get('reconstruction_error', 0), 3),
                    'trend_info': transformer_result.get('trend_info', {}),
                    'models_agree': transformer_result.get('models_agree', False)
                },
                'comparison': {
                    'models_agree': models_agree,
                    'consensus_is_anomaly': consensus_is_anomaly,
                    'agreement_score': round(agreement_score, 3),
                    'analysis_id': analysis_record.id
                }
            }
        }
    
    except HTTPException:
        raise
    except Exception as e:
        print(f"Error analyzing sensor anomalies: {e}")
        return {
            'error': str(e),
            'sensor_id': sensor_id
        }


@app.post("/api/recommendations/generate")
def generate_recommendations(request_data: dict = None, db: Session = Depends(get_db)):
    """
    üéì DIPLOMA CRITERION 1 & 2: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã—Ö —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –¥–ª—è –ø—Ä–æ–∞–∫—Ç–∏–≤–Ω–æ–≥–æ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è.
    
    –ü—Ä–æ—Ü–µ—Å—Å:
    1. –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –≤—Å–µ –¥–∞—Ç—á–∏–∫–∏ –ª–æ–∫–∞—Ü–∏–∏ –Ω–∞ –∞–Ω–æ–º–∞–ª–∏–∏
    2. –ò—Å–ø–æ–ª—å–∑—É–µ–º NLP –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ–ø–∏—Å–∞–Ω–∏–π –ø—Ä–æ–±–ª–µ–º
    3. –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∏—Å–ø–æ–ª–Ω—è–µ–º—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ —Å target_value
    4. –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—É
    
    Body:
        {
            'location_id': int,
            'only_anomalies': bool (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é true)
        }
    
    Returns:
        {
            'location_id': int,
            'location_name': str,
            'recommendations': [
                {
                    'sensor_name': str,
                    'problem_description': str,
                    'recommended_action': str,
                    'target_value': float,
                    'severity': str,
                    'priority': int,
                    'confidence': float,
                    'reasoning': str,
                    'recommendation_id': int
                }
            ]
        }
    """
    try:
        # –ü–∞—Ä—Å–∏–º —Ç–µ–ª–æ –∑–∞–ø—Ä–æ—Å–∞
        location_id = request_data.get('location_id') if request_data else None
        only_anomalies = request_data.get('only_anomalies', True) if request_data else True
        
        if not location_id:
            raise HTTPException(status_code=400, detail="location_id is required")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ª–æ–∫–∞—Ü–∏—é
        location = db.query(models.Location).filter(models.Location.id == location_id).first()
        if not location:
            raise HTTPException(status_code=404, detail="Location not found")
        
        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –¥–∞—Ç—á–∏–∫–∏ –ª–æ–∫–∞—Ü–∏–∏
        sensors = crud.get_sensors_by_location(db, location_id)
        
        # –ò–ú–ü–û–†–¢–ò–†–£–ï–ú –ú–û–î–£–õ–ò –ê–ù–ê–õ–ò–ó–ê
        from anomaly_detection_classical import moving_avg_detector
        from intelligent_recommendation_engine import RecommendationGenerator
        
        generator = RecommendationGenerator()
        recommendations = []
        
        for sensor in sensors:
            # –ü–æ–ª—É—á–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ –∏–∑–º–µ—Ä–µ–Ω–∏—è
            measurements = crud.get_sensor_measurements(db, sensor.id, days=7)
            
            if not measurements:
                continue
            
            last_measurement = measurements[-1]
            values = [m.value for m in measurements]
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –Ω–∞ –∞–Ω–æ–º–∞–ª–∏–∏
            anomaly_result = moving_avg_detector.detect(values)
            
            # –ï—Å–ª–∏ only_anomalies=True –∏ —ç—Ç–æ –Ω–µ –∞–Ω–æ–º–∞–ª–∏—è, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
            if only_anomalies and not anomaly_result['is_anomaly']:
                continue
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—é
            recommendation = generator.generate_recommendation(
                sensor_name=sensor.name,
                sensor_type=sensor.sensor_type.name,
                current_value=last_measurement.value,
                anomaly_analysis=anomaly_result,
                location_room_type=location.room_type
            )
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—é –≤ –ë–î
            rec_record = models.IntelligentRecommendation(
                sensor_id=sensor.id,
                location_id=location_id,
                problem_description=recommendation['problem_description'],
                recommended_action=recommendation['recommended_action'],
                target_value=recommendation['target_value'],
                reasoning=recommendation['reasoning'],
                confidence=recommendation['confidence'],
                severity=recommendation['severity'],
                priority=recommendation['priority']
            )
            db.add(rec_record)
            db.flush()  # –ü–æ–ª—É—á–∞–µ–º ID
            
            recommendation['recommendation_id'] = rec_record.id
            recommendation['sensor_name'] = sensor.name
            recommendations.append(recommendation)
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—É
        recommendations.sort(key=lambda x: x['priority'], reverse=True)
        
        db.commit()
        
        return {
            'location_id': location_id,
            'location_name': location.name,
            'recommendations_count': len(recommendations),
            'recommendations': recommendations
        }
    
    except HTTPException:
        raise
    except Exception as e:
        print(f"Error generating recommendations: {e}")
        return {
            'error': str(e),
            'location_id': request_data.get('location_id') if request_data else None
        }


@app.post("/api/voice/notification-command")
def process_voice_notification_command(
    audio_data: dict,
    db: Session = Depends(get_db)
):
    """
    üéì DIPLOMA CRITERION 4: –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –≥–æ–ª–æ—Å–æ–≤—ã—Ö –∫–æ–º–∞–Ω–¥ –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è–º–∏.
    
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç Whisper –¥–ª—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä–æ–≤–∞–Ω–∏—è –∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –∫–æ–º–∞–Ω–¥:
    - 'confirm' / '–¥–∞': –ü–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
    - 'reject' / '–Ω–µ—Ç': –û—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
    - 'modify' / '–∏–∑–º–µ–Ω–∏': –ò–∑–º–µ–Ω–µ–Ω–∏–µ —Ü–µ–ª–µ–≤–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è
    - 'request_info': –ó–∞–ø—Ä–æ—Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ–± –∞–Ω–æ–º–∞–ª–∏–∏
    - 'request_report': –ó–∞–ø—Ä–æ—Å –æ—Ç—á–µ—Ç–∞
    
    Body:
        {
            'audio_file_path': str,
            'notification_id': int,
            'sensor_id': int (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        }
    
    Returns:
        {
            'success': bool,
            'command': str,
            'confidence_speech': float,
            'confidence_command': float,
            'transcript': str,
            'action_taken': str,
            'voice_command_id': int
        }
    """
    try:
        audio_file_path = audio_data.get('audio_file_path')
        notification_id = audio_data.get('notification_id')
        sensor_id = audio_data.get('sensor_id')
        
        if not audio_file_path:
            raise HTTPException(status_code=400, detail="audio_file_path is required")
        
        if not notification_id:
            raise HTTPException(status_code=400, detail="notification_id is required")
        
        # –ò–ú–ü–û–†–¢–ò–†–£–ï–ú –ú–û–î–£–õ–¨ –†–ê–°–ü–û–ó–ù–ê–í–ê–ù–ò–Ø –†–ï–ß–ò
        from voice_notification_commands import voice_notification_manager
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≥–æ–ª–æ—Å–æ–≤—É—é –∫–æ–º–∞–Ω–¥—É (DIPLOMA CRITERION 4)
        voice_result = voice_notification_manager.process_notification_voice_input(
            audio_file_path=audio_file_path,
            notification_id=notification_id,
            sensor_id=sensor_id
        )
        
        if not voice_result.get('success'):
            return {
                'success': False,
                'error': voice_result.get('error', 'Unknown error'),
                'notification_id': notification_id
            }
        
        command = voice_result['command']
        transcript = voice_result['transcript']
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–æ–º–∞–Ω–¥—É –≤ –ë–î
        voice_cmd_record = models.VoiceNotificationCommand(
            notification_id=notification_id,
            transcript=transcript,
            command=command,
            execution_status='received',
            execution_timestamp=datetime.utcnow()
        )
        db.add(voice_cmd_record)
        db.flush()
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º –¥–µ–π—Å—Ç–≤–∏–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–º–∞–Ω–¥—ã
        action_taken = ''
        notification = db.query(models.Notification).filter(
            models.Notification.id == notification_id
        ).first()
        
        if command == 'confirm':
            # –û—Ç–º–µ—á–∞–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –∫–∞–∫ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥—ë–Ω–Ω–æ–µ
            notification.status = 'confirmed'
            action_taken = 'Recommendation confirmed, implementing changes'
            voice_cmd_record.execution_status = 'confirmed'
        
        elif command == 'reject':
            # –û—Ç–º–µ—á–∞–µ–º –∫–∞–∫ –æ—Ç–∫–ª–æ–Ω–µ–Ω–Ω–æ–µ
            notification.status = 'rejected'
            action_taken = 'Recommendation rejected'
            voice_cmd_record.execution_status = 'rejected'
        
        elif command == 'modify':
            # –ü—ã—Ç–∞–µ–º—Å—è –∏–∑–≤–ª–µ—á—å –Ω–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
            new_value = voice_result.get('extracted_value')
            if new_value:
                notification.required_target_value = float(new_value)
                action_taken = f'Target value modified to {new_value}'
                voice_cmd_record.execution_status = 'modified'
            else:
                action_taken = 'Modify command received but could not extract value'
                voice_cmd_record.execution_status = 'pending_clarification'
        
        elif command == 'request_info':
            action_taken = 'Information requested, sending detailed report'
            voice_cmd_record.execution_status = 'info_sent'
        
        elif command == 'request_report':
            action_taken = 'Historical report requested'
            voice_cmd_record.execution_status = 'report_sent'
        
        else:
            action_taken = 'Command not recognized'
            voice_cmd_record.execution_status = 'unknown_command'
        
        db.commit()
        
        return {
            'success': True,
            'command': command,
            'confidence_speech': voice_result['confidence_speech'],
            'confidence_command': voice_result['confidence_command'],
            'transcript': transcript,
            'detected_language': voice_result['detected_language'],
            'action_taken': action_taken,
            'voice_command_id': voice_cmd_record.id,
            'notification_id': notification_id
        }
    
    except HTTPException:
        raise
    except Exception as e:
        print(f"Error processing voice notification command: {e}")
        return {
            'success': False,
            'error': str(e),
            'notification_id': audio_data.get('notification_id') if audio_data else None
        }


@app.get("/api/diploma/analysis-stats")
def get_diploma_analysis_stats(location_id: int = None, db: Session = Depends(get_db)):
    """
    üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –≤—Å–µ–º –∫—Ä–∏—Ç–µ—Ä–∏—è–º –¥–∏–ø–ª–æ–º–Ω–æ–π —Ä–∞–±–æ—Ç—ã.
    
    –ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç:
    - –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ–≤–µ–¥—ë–Ω–Ω—ã—Ö –∞–Ω–∞–ª–∏–∑–æ–≤ (CRITERION 2&3)
    - –°—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–º –∏ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä –º–µ—Ç–æ–¥–∞–º (CRITERION 2&3)
    - –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π (CRITERION 1)
    - –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –≥–æ–ª–æ—Å–æ–≤—ã—Ö –∫–æ–º–∞–Ω–¥ (CRITERION 4)
    """
    try:
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∞–Ω–æ–º–∞–ª–∏—è–º
        anomaly_analyses = db.query(models.AnomalyAnalysis)
        if location_id:
            anomaly_analyses = anomaly_analyses.filter(models.AnomalyAnalysis.location_id == location_id)
        anomaly_analyses = anomaly_analyses.all()
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º
        recommendations = db.query(models.IntelligentRecommendation)
        if location_id:
            recommendations = recommendations.filter(models.IntelligentRecommendation.location_id == location_id)
        recommendations = recommendations.all()
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –≥–æ–ª–æ—Å–æ–≤—ã–º –∫–æ–º–∞–Ω–¥–∞–º
        voice_commands = db.query(models.VoiceNotificationCommand).all()
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        classical_anomalies = sum(1 for a in anomaly_analyses if a.classical_is_anomaly)
        transformer_anomalies = sum(1 for a in anomaly_analyses if a.transformer_is_anomaly)
        model_agreements = sum(1 for a in anomaly_analyses if a.models_agreement)
        
        voice_commands_stats = {
            'confirm': sum(1 for v in voice_commands if v.command == 'confirm'),
            'reject': sum(1 for v in voice_commands if v.command == 'reject'),
            'modify': sum(1 for v in voice_commands if v.command == 'modify'),
            'request_info': sum(1 for v in voice_commands if v.command == 'request_info'),
            'request_report': sum(1 for v in voice_commands if v.command == 'request_report'),
            'unknown': sum(1 for v in voice_commands if v.command == 'unknown')
        }
        
        return {
            'diploma_criteria': {
                'criterion_1_practical_problem': {
                    'description': 'Proactive microclimate monitoring with intelligent recommendations',
                    'implemented': True,
                    'metrics': {
                        'total_recommendations': len(recommendations),
                        'avg_confidence': round(sum(r.confidence for r in recommendations) / len(recommendations), 3) if recommendations else 0,
                        'by_severity': {
                            'critical': sum(1 for r in recommendations if r.severity == 'critical'),
                            'high': sum(1 for r in recommendations if r.severity == 'high'),
                            'medium': sum(1 for r in recommendations if r.severity == 'medium'),
                            'low': sum(1 for r in recommendations if r.severity == 'low')
                        }
                    }
                },
                'criterion_2_nlp_models': {
                    'description': 'NLP for time series analysis - Classical and Transformer methods',
                    'implemented': True,
                    'classical_methods': ['moving_average', 'isolation_forest', 'seasonal_decomposition'],
                    'transformer_methods': ['time_series_attention', 'trend_analysis', 'ensemble'],
                    'metrics': {
                        'total_analyses': len(anomaly_analyses),
                        'classical_anomalies_detected': classical_anomalies,
                        'transformer_anomalies_detected': transformer_anomalies
                    }
                },
                'criterion_3_model_comparison': {
                    'description': 'Comparison of classical vs Transformer models for anomaly detection',
                    'implemented': True,
                    'metrics': {
                        'total_comparisons': len(anomaly_analyses),
                        'model_agreements': model_agreements,
                        'agreement_rate': round(model_agreements / len(anomaly_analyses), 3) if anomaly_analyses else 0,
                        'avg_agreement_score': round(sum(a.confidence for a in anomaly_analyses) / len(anomaly_analyses), 3) if anomaly_analyses else 0
                    }
                },
                'criterion_4_speech_recognition': {
                    'description': 'Speech recognition with Whisper for notification management',
                    'implemented': True,
                    'metrics': {
                        'total_voice_commands': len(voice_commands),
                        'commands_by_type': voice_commands_stats
                    }
                }
            },
            'location_filter': location_id,
            'timestamp': datetime.utcnow().isoformat()
        }
    
    except Exception as e:
        print(f"Error getting diploma stats: {e}")
        return {
            'error': str(e)
        }